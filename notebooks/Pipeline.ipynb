{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Cosine Similarity / Nearest Neighbors\n",
    "3. Build / Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../data/beer.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "query = \"SELECT * FROM user_extract\"\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. remove duplicates \n",
    "df = df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. one-hot encode categorical variables\n",
    "categorical_variables = ['beer_description', 'brewery']\n",
    "for cat_var in categorical_variables:\n",
    "    dummies = pd.get_dummies(df[cat_var], drop_first=True, prefix=cat_var)\n",
    "    df = pd.merge(df, dummies, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ABV\n",
      "num of outliers = 3,421\n",
      "% of outliers = 3.33%\n",
      "\n",
      "\n",
      "FEATURE global_rating\n",
      "num of outliers = 3,648\n",
      "% of outliers = 3.56%\n",
      "\n",
      "\n",
      "FEATURE user_rating\n",
      "num of outliers = 11,267\n",
      "% of outliers = 10.98%\n",
      "\n",
      "\n",
      "FEATURE IBU\n",
      "SKIPPING NA VALUES\n",
      "num of outliers = 557\n",
      "% of outliers = 1.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. flag outliers\n",
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "skipnas = True\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        q1 = df[feature].quantile(.25)\n",
    "        q3 = df[feature].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (df[feature] >= q1 - 1.5*iqr) & (df[feature] <= q3 + 1.5*iqr)\n",
    "        outliers = df[~non_outlier_mask]\n",
    "\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(df)))\n",
    "        print(\"\\n\")\n",
    "    except TypeError:\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"ANALYZING ALL NON-NA VALUES\")\n",
    "        \n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        q1 = non_nas.quantile(.25)\n",
    "        q3 = non_nas.quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (non_nas >= q1 - 1.5*iqr) & (non_nas <= q3 + 1.5*iqr)\n",
    "        outliers = non_nas[~non_outlier_mask]\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(non_nas)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Impute missing values \n",
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "impute_method = 'mean'\n",
    "\n",
    "for feature in features:\n",
    "    if impute_method == 'mean':\n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        feature_mean = non_nas.mean()\n",
    "        df[feature] = df[feature].fillna(feature_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cosine Similarity / Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create User-Item Matrix \n",
    "fill_method = 'item_mean'\n",
    "\n",
    "data = df\n",
    "values = 'user_rating'\n",
    "index = 'username'\n",
    "columns = 'beer_name'\n",
    "agg_func = 'mean'\n",
    "\n",
    "if fill_method == 'item_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix = ui_matrix.fillna(ui_matrix.mean(axis=0), axis=0)\n",
    "\n",
    "elif fill_method == 'user_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "elif fill_method == 0:\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func, fill_value=0)\n",
    "else:\n",
    "    raise ValueError(\"Please checkout 'fill_method' value\")\n",
    "\n",
    "ui_matrix.columns = list(ui_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Scale / Standardize \n",
    "scale_standardize = 'standardize'\n",
    "\n",
    "if scale_standardize == 'scale':\n",
    "    print('Data is already scaled from 0 to 5')\n",
    "elif scale_standardize == 'standardize':\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    standardized_ui_matrix = pd.DataFrame(scaler.fit_transform(ui_matrix))\n",
    "    standardized_ui_matrix.index = ui_matrix.index\n",
    "    standardized_ui_matrix.columns = ui_matrix.columns\n",
    "    ui_matrix = standardized_ui_matrix\n",
    "elif scale_standardize == None:\n",
    "    print(\"Skipping scaling / standardization\")\n",
    "else:\n",
    "    raise ValueError(\"Please checkout 'scale_standardize' value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cosine Similarity \n",
    "user_of_reference = 'tsharp93'\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = ui_matrix[ui_matrix.index == user_of_reference]\n",
    "Y = ui_matrix[ui_matrix.index != user_of_reference]\n",
    "\n",
    "sim = cosine_similarity(X,Y)[0].tolist()\n",
    "names = Y.index\n",
    "\n",
    "sim_df = pd.DataFrame({'username':names, 'sim_score':sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gmlman</td>\n",
       "      <td>0.857681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Mikeylga</td>\n",
       "      <td>0.856230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MythicMan57</td>\n",
       "      <td>0.845642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>junana71</td>\n",
       "      <td>0.842739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kwitnes</td>\n",
       "      <td>0.840310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       username  sim_score\n",
       "18       Gmlman   0.857681\n",
       "34     Mikeylga   0.856230\n",
       "39  MythicMan57   0.845642\n",
       "94     junana71   0.842739\n",
       "98      kwitnes   0.840310"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.sort_values(by='sim_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_guild",
   "language": "python",
   "name": "ml_guild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
