{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Cosine Similarity / Nearest Neighbors\n",
    "3. Scale / Standardize\n",
    "4. Build / Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data \n",
    "db_path = '../data/beer.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "query = \"SELECT * FROM user_extract\"\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. remove duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. one-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['beer_description', 'brewery']\n",
    "for cat_var in categorical_variables:\n",
    "    dummies = pd.get_dummies(df[cat_var], drop_first=True, prefix=cat_var)\n",
    "    df = pd.merge(df, dummies, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. flag outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ABV\n",
      "num of outliers = 3,421\n",
      "% of outliers = 3.33%\n",
      "\n",
      "\n",
      "FEATURE global_rating\n",
      "num of outliers = 3,648\n",
      "% of outliers = 3.56%\n",
      "\n",
      "\n",
      "FEATURE user_rating\n",
      "num of outliers = 11,267\n",
      "% of outliers = 10.98%\n",
      "\n",
      "\n",
      "FEATURE IBU\n",
      "ANALYZING ALL NON-NA VALUES\n",
      "num of outliers = 557\n",
      "% of outliers = 1.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "skipnas = True\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        q1 = df[feature].quantile(.25)\n",
    "        q3 = df[feature].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (df[feature] >= q1 - 1.5*iqr) & (df[feature] <= q3 + 1.5*iqr)\n",
    "        outliers = df[~non_outlier_mask]\n",
    "\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(df)))\n",
    "        print(\"\\n\")\n",
    "    except TypeError:\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"ANALYZING ALL NON-NA VALUES\")\n",
    "        \n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        q1 = non_nas.quantile(.25)\n",
    "        q3 = non_nas.quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (non_nas >= q1 - 1.5*iqr) & (non_nas <= q3 + 1.5*iqr)\n",
    "        outliers = non_nas[~non_outlier_mask]\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(non_nas)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['user_rating'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "impute_method = 'mean'\n",
    "\n",
    "for feature in features:\n",
    "    if impute_method == 'mean':\n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        feature_mean = non_nas.mean()\n",
    "        df[feature] = df[feature].fillna(feature_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x256ceecaf28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['user_rating'])\n",
    "plt.show()\n",
    "df['user_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cosine Similarity / Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Create User-Item Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Specified Fill Method\n",
    "fill_method = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Wild Blend! (Morango+Amora)</th>\n",
       "      <th>\"33\" Export</th>\n",
       "      <th>\"Body\" System</th>\n",
       "      <th>\"British Bitter\" English Pale Ale</th>\n",
       "      <th>\"Calcium\" Blood Orange</th>\n",
       "      <th>\"Craft Beer\" Dark Lager Dry Hopped Oct. 2017</th>\n",
       "      <th>\"Cream Soda\" Wheat IPA</th>\n",
       "      <th>\"Cult of Pekko\" Hop-Scotch IPA (2017)</th>\n",
       "      <th>\"K\" is for Kriek</th>\n",
       "      <th>\"Not Just Some\" Oatmeal Stout</th>\n",
       "      <th>...</th>\n",
       "      <th>分 桃 (Fēn Táo)</th>\n",
       "      <th>分 桃 (Fēn Táo) (Blend 2)</th>\n",
       "      <th>废都 (Two Lost Capitals)</th>\n",
       "      <th>日本から来たネコ (Some Cat From Japan)</th>\n",
       "      <th>日本で人気がある Big In Japan DDH IPA</th>\n",
       "      <th>木島平村 Hard Cider #39</th>\n",
       "      <th>藻細工S-IPA (mosaic S-IPA)</th>\n",
       "      <th>調和</th>\n",
       "      <th>黄雪 (おうせき) - Yellow Snow</th>\n",
       "      <th>광화문 Seoulite Ale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFernan25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlexKress</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asier05</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audyoh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boat</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           !Wild Blend! (Morango+Amora)  \"33\" Export  \"Body\" System  \\\n",
       "username                                                              \n",
       "AFernan25                             0          0.0              0   \n",
       "AlexKress                             0          0.0              0   \n",
       "Asier05                               0          0.0              0   \n",
       "Audyoh                                0          0.0              0   \n",
       "Boat                                  4          0.0              0   \n",
       "\n",
       "           \"British Bitter\" English Pale Ale  \"Calcium\" Blood Orange  \\\n",
       "username                                                               \n",
       "AFernan25                                0.0                     0.0   \n",
       "AlexKress                                0.0                     0.0   \n",
       "Asier05                                  0.0                     0.0   \n",
       "Audyoh                                   0.0                     0.0   \n",
       "Boat                                     0.0                     0.0   \n",
       "\n",
       "           \"Craft Beer\" Dark Lager Dry Hopped Oct. 2017  \\\n",
       "username                                                  \n",
       "AFernan25                                           0.0   \n",
       "AlexKress                                           0.0   \n",
       "Asier05                                             0.0   \n",
       "Audyoh                                              0.0   \n",
       "Boat                                                0.0   \n",
       "\n",
       "           \"Cream Soda\" Wheat IPA  \"Cult of Pekko\" Hop-Scotch IPA (2017)  \\\n",
       "username                                                                   \n",
       "AFernan25                       0                                    0.0   \n",
       "AlexKress                       0                                    0.0   \n",
       "Asier05                         0                                    0.0   \n",
       "Audyoh                          0                                    0.0   \n",
       "Boat                            0                                    0.0   \n",
       "\n",
       "           \"K\" is for Kriek  \"Not Just Some\" Oatmeal Stout  ...  \\\n",
       "username                                                    ...   \n",
       "AFernan25               0.0                            0.0  ...   \n",
       "AlexKress               0.0                            0.0  ...   \n",
       "Asier05                 0.0                            0.0  ...   \n",
       "Audyoh                  0.0                            0.0  ...   \n",
       "Boat                    0.0                            0.0  ...   \n",
       "\n",
       "           分 桃 (Fēn Táo)  分 桃 (Fēn Táo) (Blend 2)  废都 (Two Lost Capitals)  \\\n",
       "username                                                                    \n",
       "AFernan25              0                      0.0                       0   \n",
       "AlexKress              0                      0.0                       0   \n",
       "Asier05                0                      0.0                       0   \n",
       "Audyoh                 0                      0.0                       0   \n",
       "Boat                   0                      0.0                       0   \n",
       "\n",
       "           日本から来たネコ (Some Cat From Japan)  日本で人気がある Big In Japan DDH IPA  \\\n",
       "username                                                                   \n",
       "AFernan25                               0                              0   \n",
       "AlexKress                               0                              0   \n",
       "Asier05                                 0                              0   \n",
       "Audyoh                                  0                              0   \n",
       "Boat                                    0                              0   \n",
       "\n",
       "           木島平村 Hard Cider #39  藻細工S-IPA (mosaic S-IPA)   調和  \\\n",
       "username                                                       \n",
       "AFernan25                  0.0                      0.0  0.0   \n",
       "AlexKress                  0.0                      0.0  0.0   \n",
       "Asier05                    0.0                      0.0  0.0   \n",
       "Audyoh                     0.0                      0.0  0.0   \n",
       "Boat                       0.0                      0.0  0.0   \n",
       "\n",
       "           黄雪 (おうせき) - Yellow Snow  광화문 Seoulite Ale  \n",
       "username                                              \n",
       "AFernan25                      0.0               0.0  \n",
       "AlexKress                      0.0               0.0  \n",
       "Asier05                        0.0               0.0  \n",
       "Audyoh                         0.0               0.0  \n",
       "Boat                           0.0               0.0  \n",
       "\n",
       "[5 rows x 56776 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create User-Item Matrix \n",
    "data = df\n",
    "values = 'user_rating'\n",
    "index = 'username'\n",
    "columns = 'beer_name'\n",
    "agg_func = 'mean'\n",
    "\n",
    "if fill_method == 'item_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix = ui_matrix.fillna(ui_matrix.mean(axis=0), axis=0)\n",
    "\n",
    "elif fill_method == 'user_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "elif fill_method == 0:\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func, fill_value=0)\n",
    "else:\n",
    "    raise ValueError(\"Please checkout 'fill_method' value\")\n",
    "\n",
    "ui_matrix.columns = list(ui_matrix.columns)\n",
    "\n",
    "ui_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User of Reference for Cosine Sim = tsharp93\n"
     ]
    }
   ],
   "source": [
    "# Calculate Cosine Similarity \n",
    "user_of_reference = 'tsharp93'\n",
    "print(\"User of Reference for Cosine Sim = {}\".format(user_of_reference))\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = ui_matrix[ui_matrix.index == user_of_reference]\n",
    "Y = ui_matrix[ui_matrix.index != user_of_reference]\n",
    "\n",
    "sim = cosine_similarity(X,Y)[0].tolist()\n",
    "names = Y.index\n",
    "\n",
    "sim_df = pd.DataFrame({'username':names, 'sim_score':sim})\n",
    "sim_df = sim_df.sort_values(by='sim_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>r4ymond</td>\n",
       "      <td>0.059821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>edufontanez</td>\n",
       "      <td>0.054202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFernan25</td>\n",
       "      <td>0.051696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FernandoRamirez</td>\n",
       "      <td>0.049640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>mikeyjimenez</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  sim_score\n",
       "110          r4ymond   0.059821\n",
       "82       edufontanez   0.054202\n",
       "0          AFernan25   0.051696\n",
       "15   FernandoRamirez   0.049640\n",
       "103     mikeyjimenez   0.048229"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Add Nearest Neighbor (Cosine Sim) Rank to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add neighbor rank to df\n",
    "neighbor_rank = sim_df.reset_index(drop=True)\n",
    "neighbor_rank.index.name = 'nearest_neighbor_rank'\n",
    "neighbor_rank.reset_index(inplace=True)\n",
    "neighbor_rank['nearest_neighbor_rank'] = neighbor_rank['nearest_neighbor_rank'] + 1\n",
    "neighbor_rank = neighbor_rank[['nearest_neighbor_rank', 'username']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearest_neighbor_rank</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>r4ymond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>edufontanez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AFernan25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FernandoRamirez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mikeyjimenez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nearest_neighbor_rank         username\n",
       "0                      1          r4ymond\n",
       "1                      2      edufontanez\n",
       "2                      3        AFernan25\n",
       "3                      4  FernandoRamirez\n",
       "4                      5     mikeyjimenez"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102598, 8347)\n",
      "(102598, 8348)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = pd.merge(neighbor_rank, df, on='username', how='outer')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearest_neighbor_rank</th>\n",
       "      <th>username</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>brewery</th>\n",
       "      <th>ABV</th>\n",
       "      <th>IBU</th>\n",
       "      <th>global_rating</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>first_date</th>\n",
       "      <th>...</th>\n",
       "      <th>brewery_Токсовская Сидрерия (On The Bones)</th>\n",
       "      <th>brewery_Тощий Заяц</th>\n",
       "      <th>brewery_Уманьпиво</th>\n",
       "      <th>brewery_Ферментстейшн</th>\n",
       "      <th>brewery_Фонтан / Кваспром</th>\n",
       "      <th>brewery_Хадыженский Пивзавод</th>\n",
       "      <th>brewery_Хмельной Патрик</th>\n",
       "      <th>brewery_Частная пивоварня Joker</th>\n",
       "      <th>brewery_Чисто пивоварня</th>\n",
       "      <th>brewery_Южный пивовар</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102558</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Firestone Lager</td>\n",
       "      <td>Lager - Helles</td>\n",
       "      <td>Firestone Walker Brewing Company</td>\n",
       "      <td>4.5</td>\n",
       "      <td>17</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.50</td>\n",
       "      <td>06/23/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Köstritzer Schwarzbier</td>\n",
       "      <td>Schwarzbier</td>\n",
       "      <td>Köstritzer Schwarzbierbrauerei</td>\n",
       "      <td>4.8</td>\n",
       "      <td>22</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.25</td>\n",
       "      <td>06/11/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Midas Touch</td>\n",
       "      <td>Gruit / Ancient Herbed Ale</td>\n",
       "      <td>Dogfish Head Craft Brewery</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.25</td>\n",
       "      <td>06/01/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Twisted Monkey</td>\n",
       "      <td>Belgian Blonde</td>\n",
       "      <td>Victory Brewing Company</td>\n",
       "      <td>5.8</td>\n",
       "      <td>15</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.00</td>\n",
       "      <td>06/01/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Fresh Squeezed IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>Deschutes Brewery</td>\n",
       "      <td>6.4</td>\n",
       "      <td>60</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.25</td>\n",
       "      <td>05/21/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nearest_neighbor_rank  username               beer_name  \\\n",
       "102558                    NaN  tsharp93         Firestone Lager   \n",
       "102559                    NaN  tsharp93  Köstritzer Schwarzbier   \n",
       "102560                    NaN  tsharp93             Midas Touch   \n",
       "102561                    NaN  tsharp93          Twisted Monkey   \n",
       "102562                    NaN  tsharp93      Fresh Squeezed IPA   \n",
       "\n",
       "                  beer_description                           brewery  ABV IBU  \\\n",
       "102558              Lager - Helles  Firestone Walker Brewing Company  4.5  17   \n",
       "102559                 Schwarzbier    Köstritzer Schwarzbierbrauerei  4.8  22   \n",
       "102560  Gruit / Ancient Herbed Ale        Dogfish Head Craft Brewery  9.0  12   \n",
       "102561              Belgian Blonde           Victory Brewing Company  5.8  15   \n",
       "102562              IPA - American                 Deschutes Brewery  6.4  60   \n",
       "\n",
       "        global_rating  user_rating first_date  ...  \\\n",
       "102558           3.58         3.50   06/23/19  ...   \n",
       "102559           3.53         3.25   06/11/19  ...   \n",
       "102560           3.78         3.25   06/01/19  ...   \n",
       "102561           3.46         4.00   06/01/19  ...   \n",
       "102562           3.94         4.25   05/21/19  ...   \n",
       "\n",
       "       brewery_Токсовская Сидрерия (On The Bones)  brewery_Тощий Заяц  \\\n",
       "102558                                          0                   0   \n",
       "102559                                          0                   0   \n",
       "102560                                          0                   0   \n",
       "102561                                          0                   0   \n",
       "102562                                          0                   0   \n",
       "\n",
       "        brewery_Уманьпиво  brewery_Ферментстейшн  brewery_Фонтан / Кваспром  \\\n",
       "102558                  0                      0                          0   \n",
       "102559                  0                      0                          0   \n",
       "102560                  0                      0                          0   \n",
       "102561                  0                      0                          0   \n",
       "102562                  0                      0                          0   \n",
       "\n",
       "        brewery_Хадыженский Пивзавод  brewery_Хмельной Патрик  \\\n",
       "102558                             0                        0   \n",
       "102559                             0                        0   \n",
       "102560                             0                        0   \n",
       "102561                             0                        0   \n",
       "102562                             0                        0   \n",
       "\n",
       "        brewery_Частная пивоварня Joker  brewery_Чисто пивоварня  \\\n",
       "102558                                0                        0   \n",
       "102559                                0                        0   \n",
       "102560                                0                        0   \n",
       "102561                                0                        0   \n",
       "102562                                0                        0   \n",
       "\n",
       "        brewery_Южный пивовар  \n",
       "102558                      0  \n",
       "102559                      0  \n",
       "102560                      0  \n",
       "102561                      0  \n",
       "102562                      0  \n",
       "\n",
       "[5 rows x 8348 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['username'] == 'tsharp93'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale / Standardize Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMINDER User of Reference = tsharp93\n"
     ]
    }
   ],
   "source": [
    "brewery_cols = [col for col in df if col.startswith('brewery_')]\n",
    "beer_description_cols = [col for col in df if col.startswith('beer_description_')]\n",
    "\n",
    "features = ['ABV', 'IBU', 'global_rating'] + beer_description_cols\n",
    "target = 'user_rating'\n",
    "\n",
    "print(\"REMINDER User of Reference = {}\".format(user_of_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Features and Target Separately (easier to Inverse Transform later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(df[features])\n",
    "df[features] = X_scaler.transform(df[features])\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y = np.array(df[target]).reshape(-1, 1 )\n",
    "y_scaler.fit(y)\n",
    "df[target] = y_scaler.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Take Top Nearest NEighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 5, # Points = 1,175\n",
      "N = 6, # Points = 1,375\n",
      "N = 7, # Points = 1,450\n",
      "N = 8, # Points = 3,750\n",
      "N = 9, # Points = 5,125\n",
      "N = 10, # Points = 7,700\n"
     ]
    }
   ],
   "source": [
    "n_users_list = range(5,11)\n",
    "\n",
    "for n in n_users_list:\n",
    "    top_n = list(sim_df.sort_values('sim_score', ascending=False)[0:n]['username'])\n",
    "    top_n_df = df[df['username'].isin(top_n)]\n",
    "    print(\"N = {}, # Points = {:,d}\".format(n, len(top_n_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso, Search for Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38225 for n = 5 with alpha = 0.0409\n",
      "MAE = 0.38331 for n = 6 with alpha = 0.02664\n",
      "MAE = 0.37284 for n = 7 with alpha = 0.02353\n",
      "MAE = 0.3762 for n = 8 with alpha = 0.01941\n",
      "MAE = 0.3751 for n = 9 with alpha = 0.01236\n",
      "MAE = 0.37668 for n = 10 with alpha = 0.0108\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import LassoCV\n",
    "    model = LassoCV(fit_intercept=False, normalize=False, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae, 5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5))\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet, Search for Alpha, L1 Ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38198 for n = 5 with alpha = 0.07629 and l1 ratio =  0.5\n",
      "MAE = 0.38399 for n = 6 with alpha = 0.04969 and l1 ratio =  0.5\n",
      "MAE = 0.37297 for n = 7 with alpha = 0.04706 and l1 ratio =  0.5\n",
      "MAE = 0.37664 for n = 8 with alpha = 0.03882 and l1 ratio =  0.5\n",
      "MAE = 0.37511 for n = 9 with alpha = 0.02473 and l1 ratio =  0.5\n",
      "MAE = 0.37674 for n = 10 with alpha = 0.02161 and l1 ratio =  0.5\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(fit_intercept=False, normalize=False, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5), \"and l1 ratio = \", model.l1_ratio_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR, C = 0.5, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38731 for n = 5 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39794 for n = 6 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39201 for n = 7 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39196 for n = 8 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.36873 for n = 9 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.3656 for n = 10 with C = 0.5 and epsilon = 0.25\n"
     ]
    }
   ],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import SVR\n",
    "    for C in [0.5]:\n",
    "        model = SVR(kernel='linear', epsilon=eps, C=C, random_state=rand_state)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model on user's data \n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        # unscale\n",
    "        preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "        y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "        # evaluate results\n",
    "        results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "        results_df.columns = ['predicted', 'actual']\n",
    "        results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "        results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "        # Performance Metrics \n",
    "        mae = np.mean(results_df['abs_error'])\n",
    "        print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "              \"with C =\", model.C, \"and epsilon =\", model.epsilon)\n",
    "\n",
    "        quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "        half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "        mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR, Search for C, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.0001, 0.1, 0.2, 0.5, 0.7, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38748 for n = 5 with final params = {'C': 0.2, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.39793 for n = 6 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.3915 for n = 7 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.39196 for n = 8 with final params = {'C': 0.5, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.3688 for n = 9 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.3656 for n = 10 with final params = {'C': 1.0, 'epsilon': 0.25, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': [eps],\n",
    "            'kernel':['linear']}\n",
    "    svr = SVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error', random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some new models..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR, Search for C, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.0001, 0.1, 0.2, 0.5, 0.7, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import LinearSVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': [eps],\n",
    "            'fit_intecerpt':[False],\n",
    "            'loss': ['epsilon_insensitive'],\n",
    "            'dual':[False],\n",
    "            'random_state':[rand_state]}\n",
    "    svr = LinearSVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error', random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet, Search for Alpha, Search for L1 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio_space = [.1, .5, .7, .9, .95, .99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38198 for n = 5 with alpha = 0.07629 and l1 ratio =  0.5\n",
      "MAE = 0.38399 for n = 6 with alpha = 0.04969 and l1 ratio =  0.5\n",
      "MAE = 0.37297 for n = 7 with alpha = 0.04706 and l1 ratio =  0.5\n",
      "MAE = 0.37664 for n = 8 with alpha = 0.03882 and l1 ratio =  0.5\n",
      "MAE = 0.3751 for n = 9 with alpha = 0.1153 and l1 ratio =  0.1\n",
      "MAE = 0.37636 for n = 10 with alpha = 0.08173 and l1 ratio =  0.1\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(fit_intercept=False, normalize=False, l1_ratio=l1_ratio_space, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5), \"and l1 ratio = \", model.l1_ratio_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Estimators and Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty estimator dictionary\n",
    "estimator_dict = {}\n",
    "\n",
    "\n",
    "# import GridSearchCV and desired estimators\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# create models and grids \n",
    "estimator = Lasso()\n",
    "grid = {\n",
    "    'fit_intercept': [False],\n",
    "    'normalize': [False]\n",
    "}\n",
    "estimator_dict['elasticnet'] = {'estimator':estimator, 'grid':grid}\n",
    "\n",
    "\n",
    "estimator = ElasticNet()\n",
    "grid = {\n",
    "    'fit_intercept': [False],\n",
    "    'normalize': [False]\n",
    "}\n",
    "estimator_dict['elasticnet'] = {'estimator':estimator, 'grid':grid}\n",
    "\n",
    "\n",
    "# estimator = SVR()\n",
    "# grid = {\n",
    "#     'epsilon': np.linspace(0.25/2, 0.5, 10),\n",
    "#     'C': np.linspace(1.0, 10, 10),\n",
    "#     'fit_intercept': [True, False],\n",
    "#     'max_iter': [10000]\n",
    "# }\n",
    "\n",
    "estimator_dict['linearsvr'] = {'estimator':estimator, 'grid':grid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Set Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_gridsearchCV(estimator_dict, X_train, y_train):\n",
    "    \n",
    "    # grid search for each estimator, store best params and scores for each estimator\n",
    "    for key in estimator_dict.keys():\n",
    "        \n",
    "        # build gridsearchcv\n",
    "        gridsearchcv = GridSearchCV(estimator = estimator_dict[key]['estimator'], \n",
    "                                    param_grid = estimator_dict[key]['grid'],\n",
    "                                    cv=3, scoring=scoring, return_train_score=True, iid=True)\n",
    "\n",
    "        # silence SVR convergence warnings \n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore', 'Liblinear failed to converge,*')\n",
    "\n",
    "        # fit gridsearchcv\n",
    "        gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "        # gather results \n",
    "        estimator_dict[key]['nearest_neighbors'] = 'ALL'\n",
    "        estimator_dict[key]['n_training_points'] = len(X_train)\n",
    "        estimator_dict[key]['best_params'] = gridsearchcv.best_params_\n",
    "        estimator_dict[key][scoring] = gridsearchcv.best_score_\n",
    "        estimator_dict[key]['stdev'] = gridsearchcv.cv_results_['std_test_score'][gridsearchcv.best_index_]\n",
    "        \n",
    "        results_dict = estimator_dict\n",
    "\n",
    "    return(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_guild",
   "language": "python",
   "name": "ml_guild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
