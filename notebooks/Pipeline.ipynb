{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "2. Cosine Similarity / Nearest Neighbors\n",
    "3. Scale / Standardize\n",
    "4. Build / Test Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data \n",
    "db_path = '../data/beer.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "query = \"SELECT * FROM user_extract\"\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. remove duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. one-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['beer_description', 'brewery']\n",
    "for cat_var in categorical_variables:\n",
    "    dummies = pd.get_dummies(df[cat_var], drop_first=True, prefix=cat_var)\n",
    "    df = pd.merge(df, dummies, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. flag outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE ABV\n",
      "num of outliers = 3,421\n",
      "% of outliers = 3.33%\n",
      "\n",
      "\n",
      "FEATURE global_rating\n",
      "num of outliers = 3,648\n",
      "% of outliers = 3.56%\n",
      "\n",
      "\n",
      "FEATURE user_rating\n",
      "num of outliers = 11,267\n",
      "% of outliers = 10.98%\n",
      "\n",
      "\n",
      "FEATURE IBU\n",
      "ANALYZING ALL NON-NA VALUES\n",
      "num of outliers = 557\n",
      "% of outliers = 1.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "skipnas = True\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        q1 = df[feature].quantile(.25)\n",
    "        q3 = df[feature].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (df[feature] >= q1 - 1.5*iqr) & (df[feature] <= q3 + 1.5*iqr)\n",
    "        outliers = df[~non_outlier_mask]\n",
    "\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(df)))\n",
    "        print(\"\\n\")\n",
    "    except TypeError:\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"ANALYZING ALL NON-NA VALUES\")\n",
    "        \n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        q1 = non_nas.quantile(.25)\n",
    "        q3 = non_nas.quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (non_nas >= q1 - 1.5*iqr) & (non_nas <= q3 + 1.5*iqr)\n",
    "        outliers = non_nas[~non_outlier_mask]\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(non_nas)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df['user_rating'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ABV', 'global_rating', 'user_rating', 'IBU']\n",
    "impute_method = 'mean'\n",
    "\n",
    "for feature in features:\n",
    "    if impute_method == 'mean':\n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        feature_mean = non_nas.mean()\n",
    "        df[feature] = df[feature].fillna(feature_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f34bba83048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df['user_rating'])\n",
    "plt.show()\n",
    "df['user_rating'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take another look at 'user_rating' outliers after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE user_rating\n",
      "num of outliers = 7,385\n",
      "% of outliers = 7.20%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['user_rating']\n",
    "skipnas = True\n",
    "\n",
    "for feature in features:\n",
    "    try:\n",
    "        q1 = df[feature].quantile(.25)\n",
    "        q3 = df[feature].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (df[feature] >= q1 - 1.5*iqr) & (df[feature] <= q3 + 1.5*iqr)\n",
    "        outliers = df[~non_outlier_mask]\n",
    "\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(df)))\n",
    "        print(\"\\n\")\n",
    "    except TypeError:\n",
    "        print(\"FEATURE {}\".format(feature))\n",
    "        print(\"ANALYZING ALL NON-NA VALUES\")\n",
    "        \n",
    "        non_nas = df[~df[feature].isna()][feature].astype(float)\n",
    "        q1 = non_nas.quantile(.25)\n",
    "        q3 = non_nas.quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        non_outlier_mask = (non_nas >= q1 - 1.5*iqr) & (non_nas <= q3 + 1.5*iqr)\n",
    "        outliers = non_nas[~non_outlier_mask]\n",
    "        print(\"num of outliers = {:,d}\".format(len(outliers)))\n",
    "        print(\"% of outliers = {:.2f}%\".format(100*len(outliers)/len(non_nas)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cosine Similarity / Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Create User-Item Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Specified Fill Method\n",
    "fill_method = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!Wild Blend! (Morango+Amora)</th>\n",
       "      <th>\"33\" Export</th>\n",
       "      <th>\"Body\" System</th>\n",
       "      <th>\"British Bitter\" English Pale Ale</th>\n",
       "      <th>\"Calcium\" Blood Orange</th>\n",
       "      <th>\"Craft Beer\" Dark Lager Dry Hopped Oct. 2017</th>\n",
       "      <th>\"Cream Soda\" Wheat IPA</th>\n",
       "      <th>\"Cult of Pekko\" Hop-Scotch IPA (2017)</th>\n",
       "      <th>\"K\" is for Kriek</th>\n",
       "      <th>\"Not Just Some\" Oatmeal Stout</th>\n",
       "      <th>...</th>\n",
       "      <th>分 桃 (Fēn Táo)</th>\n",
       "      <th>分 桃 (Fēn Táo) (Blend 2)</th>\n",
       "      <th>废都 (Two Lost Capitals)</th>\n",
       "      <th>日本から来たネコ (Some Cat From Japan)</th>\n",
       "      <th>日本で人気がある Big In Japan DDH IPA</th>\n",
       "      <th>木島平村 Hard Cider #39</th>\n",
       "      <th>藻細工S-IPA (mosaic S-IPA)</th>\n",
       "      <th>調和</th>\n",
       "      <th>黄雪 (おうせき) - Yellow Snow</th>\n",
       "      <th>광화문 Seoulite Ale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFernan25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlexKress</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asier05</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audyoh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boat</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56776 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           !Wild Blend! (Morango+Amora)  \"33\" Export  \"Body\" System  \\\n",
       "username                                                              \n",
       "AFernan25                             0          0.0              0   \n",
       "AlexKress                             0          0.0              0   \n",
       "Asier05                               0          0.0              0   \n",
       "Audyoh                                0          0.0              0   \n",
       "Boat                                  4          0.0              0   \n",
       "\n",
       "           \"British Bitter\" English Pale Ale  \"Calcium\" Blood Orange  \\\n",
       "username                                                               \n",
       "AFernan25                                0.0                     0.0   \n",
       "AlexKress                                0.0                     0.0   \n",
       "Asier05                                  0.0                     0.0   \n",
       "Audyoh                                   0.0                     0.0   \n",
       "Boat                                     0.0                     0.0   \n",
       "\n",
       "           \"Craft Beer\" Dark Lager Dry Hopped Oct. 2017  \\\n",
       "username                                                  \n",
       "AFernan25                                           0.0   \n",
       "AlexKress                                           0.0   \n",
       "Asier05                                             0.0   \n",
       "Audyoh                                              0.0   \n",
       "Boat                                                0.0   \n",
       "\n",
       "           \"Cream Soda\" Wheat IPA  \"Cult of Pekko\" Hop-Scotch IPA (2017)  \\\n",
       "username                                                                   \n",
       "AFernan25                       0                                    0.0   \n",
       "AlexKress                       0                                    0.0   \n",
       "Asier05                         0                                    0.0   \n",
       "Audyoh                          0                                    0.0   \n",
       "Boat                            0                                    0.0   \n",
       "\n",
       "           \"K\" is for Kriek  \"Not Just Some\" Oatmeal Stout  ...  \\\n",
       "username                                                    ...   \n",
       "AFernan25               0.0                            0.0  ...   \n",
       "AlexKress               0.0                            0.0  ...   \n",
       "Asier05                 0.0                            0.0  ...   \n",
       "Audyoh                  0.0                            0.0  ...   \n",
       "Boat                    0.0                            0.0  ...   \n",
       "\n",
       "           分 桃 (Fēn Táo)  分 桃 (Fēn Táo) (Blend 2)  废都 (Two Lost Capitals)  \\\n",
       "username                                                                    \n",
       "AFernan25              0                      0.0                       0   \n",
       "AlexKress              0                      0.0                       0   \n",
       "Asier05                0                      0.0                       0   \n",
       "Audyoh                 0                      0.0                       0   \n",
       "Boat                   0                      0.0                       0   \n",
       "\n",
       "           日本から来たネコ (Some Cat From Japan)  日本で人気がある Big In Japan DDH IPA  \\\n",
       "username                                                                   \n",
       "AFernan25                               0                              0   \n",
       "AlexKress                               0                              0   \n",
       "Asier05                                 0                              0   \n",
       "Audyoh                                  0                              0   \n",
       "Boat                                    0                              0   \n",
       "\n",
       "           木島平村 Hard Cider #39  藻細工S-IPA (mosaic S-IPA)   調和  \\\n",
       "username                                                       \n",
       "AFernan25                  0.0                      0.0  0.0   \n",
       "AlexKress                  0.0                      0.0  0.0   \n",
       "Asier05                    0.0                      0.0  0.0   \n",
       "Audyoh                     0.0                      0.0  0.0   \n",
       "Boat                       0.0                      0.0  0.0   \n",
       "\n",
       "           黄雪 (おうせき) - Yellow Snow  광화문 Seoulite Ale  \n",
       "username                                              \n",
       "AFernan25                      0.0               0.0  \n",
       "AlexKress                      0.0               0.0  \n",
       "Asier05                        0.0               0.0  \n",
       "Audyoh                         0.0               0.0  \n",
       "Boat                           0.0               0.0  \n",
       "\n",
       "[5 rows x 56776 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create User-Item Matrix \n",
    "data = df\n",
    "values = 'user_rating'\n",
    "index = 'username'\n",
    "columns = 'beer_name'\n",
    "agg_func = 'mean'\n",
    "\n",
    "if fill_method == 'item_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix = ui_matrix.fillna(ui_matrix.mean(axis=0), axis=0)\n",
    "\n",
    "elif fill_method == 'user_mean':\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func)\n",
    "    ui_matrix.apply(lambda row: row.fillna(row.mean()), axis=1)\n",
    "\n",
    "elif fill_method == 0:\n",
    "    ui_matrix = pd.pivot_table(data=data, values=values, index=index, \n",
    "                               columns=columns, aggfunc=agg_func, fill_value=0)\n",
    "else:\n",
    "    raise ValueError(\"Please checkout 'fill_method' value\")\n",
    "\n",
    "ui_matrix.columns = list(ui_matrix.columns)\n",
    "\n",
    "ui_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User of Reference for Cosine Sim = tsharp93\n"
     ]
    }
   ],
   "source": [
    "# Calculate Cosine Similarity \n",
    "user_of_reference = 'tsharp93'\n",
    "print(\"User of Reference for Cosine Sim = {}\".format(user_of_reference))\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X = ui_matrix[ui_matrix.index == user_of_reference]\n",
    "Y = ui_matrix[ui_matrix.index != user_of_reference]\n",
    "\n",
    "sim = cosine_similarity(X,Y)[0].tolist()\n",
    "names = Y.index\n",
    "\n",
    "sim_df = pd.DataFrame({'username':names, 'sim_score':sim})\n",
    "sim_df = sim_df.sort_values(by='sim_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>r4ymond</td>\n",
       "      <td>0.059821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>edufontanez</td>\n",
       "      <td>0.054202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFernan25</td>\n",
       "      <td>0.051696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>FernandoRamirez</td>\n",
       "      <td>0.049640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>mikeyjimenez</td>\n",
       "      <td>0.048229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  sim_score\n",
       "110          r4ymond   0.059821\n",
       "82       edufontanez   0.054202\n",
       "0          AFernan25   0.051696\n",
       "15   FernandoRamirez   0.049640\n",
       "103     mikeyjimenez   0.048229"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Add Nearest Neighbor (Cosine Sim) Rank to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add neighbor rank to df\n",
    "neighbor_rank = sim_df.reset_index(drop=True)\n",
    "neighbor_rank.index.name = 'nearest_neighbor_rank'\n",
    "neighbor_rank.reset_index(inplace=True)\n",
    "neighbor_rank['nearest_neighbor_rank'] = neighbor_rank['nearest_neighbor_rank'] + 1\n",
    "neighbor_rank = neighbor_rank[['nearest_neighbor_rank', 'username']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearest_neighbor_rank</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>r4ymond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>edufontanez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AFernan25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FernandoRamirez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mikeyjimenez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nearest_neighbor_rank         username\n",
       "0                      1          r4ymond\n",
       "1                      2      edufontanez\n",
       "2                      3        AFernan25\n",
       "3                      4  FernandoRamirez\n",
       "4                      5     mikeyjimenez"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102598, 8347)\n",
      "(102598, 8348)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = pd.merge(neighbor_rank, df, on='username', how='outer')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nearest_neighbor_rank</th>\n",
       "      <th>username</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_description</th>\n",
       "      <th>brewery</th>\n",
       "      <th>ABV</th>\n",
       "      <th>IBU</th>\n",
       "      <th>global_rating</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>first_date</th>\n",
       "      <th>...</th>\n",
       "      <th>brewery_Токсовская Сидрерия (On The Bones)</th>\n",
       "      <th>brewery_Тощий Заяц</th>\n",
       "      <th>brewery_Уманьпиво</th>\n",
       "      <th>brewery_Ферментстейшн</th>\n",
       "      <th>brewery_Фонтан / Кваспром</th>\n",
       "      <th>brewery_Хадыженский Пивзавод</th>\n",
       "      <th>brewery_Хмельной Патрик</th>\n",
       "      <th>brewery_Частная пивоварня Joker</th>\n",
       "      <th>brewery_Чисто пивоварня</th>\n",
       "      <th>brewery_Южный пивовар</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102558</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Firestone Lager</td>\n",
       "      <td>Lager - Helles</td>\n",
       "      <td>Firestone Walker Brewing Company</td>\n",
       "      <td>4.5</td>\n",
       "      <td>17</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.50</td>\n",
       "      <td>06/23/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Köstritzer Schwarzbier</td>\n",
       "      <td>Schwarzbier</td>\n",
       "      <td>Köstritzer Schwarzbierbrauerei</td>\n",
       "      <td>4.8</td>\n",
       "      <td>22</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.25</td>\n",
       "      <td>06/11/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Midas Touch</td>\n",
       "      <td>Gruit / Ancient Herbed Ale</td>\n",
       "      <td>Dogfish Head Craft Brewery</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.25</td>\n",
       "      <td>06/01/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102561</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Twisted Monkey</td>\n",
       "      <td>Belgian Blonde</td>\n",
       "      <td>Victory Brewing Company</td>\n",
       "      <td>5.8</td>\n",
       "      <td>15</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.00</td>\n",
       "      <td>06/01/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>tsharp93</td>\n",
       "      <td>Fresh Squeezed IPA</td>\n",
       "      <td>IPA - American</td>\n",
       "      <td>Deschutes Brewery</td>\n",
       "      <td>6.4</td>\n",
       "      <td>60</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.25</td>\n",
       "      <td>05/21/19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        nearest_neighbor_rank  username               beer_name  \\\n",
       "102558                    NaN  tsharp93         Firestone Lager   \n",
       "102559                    NaN  tsharp93  Köstritzer Schwarzbier   \n",
       "102560                    NaN  tsharp93             Midas Touch   \n",
       "102561                    NaN  tsharp93          Twisted Monkey   \n",
       "102562                    NaN  tsharp93      Fresh Squeezed IPA   \n",
       "\n",
       "                  beer_description                           brewery  ABV IBU  \\\n",
       "102558              Lager - Helles  Firestone Walker Brewing Company  4.5  17   \n",
       "102559                 Schwarzbier    Köstritzer Schwarzbierbrauerei  4.8  22   \n",
       "102560  Gruit / Ancient Herbed Ale        Dogfish Head Craft Brewery  9.0  12   \n",
       "102561              Belgian Blonde           Victory Brewing Company  5.8  15   \n",
       "102562              IPA - American                 Deschutes Brewery  6.4  60   \n",
       "\n",
       "        global_rating  user_rating first_date  ...  \\\n",
       "102558           3.58         3.50   06/23/19  ...   \n",
       "102559           3.53         3.25   06/11/19  ...   \n",
       "102560           3.78         3.25   06/01/19  ...   \n",
       "102561           3.46         4.00   06/01/19  ...   \n",
       "102562           3.94         4.25   05/21/19  ...   \n",
       "\n",
       "       brewery_Токсовская Сидрерия (On The Bones)  brewery_Тощий Заяц  \\\n",
       "102558                                          0                   0   \n",
       "102559                                          0                   0   \n",
       "102560                                          0                   0   \n",
       "102561                                          0                   0   \n",
       "102562                                          0                   0   \n",
       "\n",
       "        brewery_Уманьпиво  brewery_Ферментстейшн  brewery_Фонтан / Кваспром  \\\n",
       "102558                  0                      0                          0   \n",
       "102559                  0                      0                          0   \n",
       "102560                  0                      0                          0   \n",
       "102561                  0                      0                          0   \n",
       "102562                  0                      0                          0   \n",
       "\n",
       "        brewery_Хадыженский Пивзавод  brewery_Хмельной Патрик  \\\n",
       "102558                             0                        0   \n",
       "102559                             0                        0   \n",
       "102560                             0                        0   \n",
       "102561                             0                        0   \n",
       "102562                             0                        0   \n",
       "\n",
       "        brewery_Частная пивоварня Joker  brewery_Чисто пивоварня  \\\n",
       "102558                                0                        0   \n",
       "102559                                0                        0   \n",
       "102560                                0                        0   \n",
       "102561                                0                        0   \n",
       "102562                                0                        0   \n",
       "\n",
       "        brewery_Южный пивовар  \n",
       "102558                      0  \n",
       "102559                      0  \n",
       "102560                      0  \n",
       "102561                      0  \n",
       "102562                      0  \n",
       "\n",
       "[5 rows x 8348 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['username'] == 'tsharp93'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale / Standardize Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMINDER User of Reference = tsharp93\n"
     ]
    }
   ],
   "source": [
    "brewery_cols = [col for col in df if col.startswith('brewery_')]\n",
    "beer_description_cols = [col for col in df if col.startswith('beer_description_')]\n",
    "\n",
    "features = ['ABV', 'IBU', 'global_rating'] + beer_description_cols\n",
    "target = 'user_rating'\n",
    "\n",
    "print(\"REMINDER User of Reference = {}\".format(user_of_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Features and Target Separately (easier to Inverse Transform later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, float64, object were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(df[features])\n",
    "df[features] = X_scaler.transform(df[features])\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y = np.array(df[target]).reshape(-1, 1 )\n",
    "y_scaler.fit(y)\n",
    "df[target] = y_scaler.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Take Top Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 5, # Points = 1,175\n",
      "N = 6, # Points = 1,375\n",
      "N = 7, # Points = 1,450\n",
      "N = 8, # Points = 3,750\n",
      "N = 9, # Points = 5,125\n",
      "N = 10, # Points = 7,700\n"
     ]
    }
   ],
   "source": [
    "n_users_list = range(5,11)\n",
    "\n",
    "for n in n_users_list:\n",
    "    top_n = list(sim_df.sort_values('sim_score', ascending=False)[0:n]['username'])\n",
    "    top_n_df = df[df['username'].isin(top_n)]\n",
    "    print(\"N = {}, # Points = {:,d}\".format(n, len(top_n_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso, Search for Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38225 for n = 5 with alpha = 0.0409\n",
      "MAE = 0.38331 for n = 6 with alpha = 0.02664\n",
      "MAE = 0.37284 for n = 7 with alpha = 0.02353\n",
      "MAE = 0.3762 for n = 8 with alpha = 0.01941\n",
      "MAE = 0.3751 for n = 9 with alpha = 0.01236\n",
      "MAE = 0.37668 for n = 10 with alpha = 0.0108\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import LassoCV\n",
    "    model = LassoCV(fit_intercept=False, normalize=False, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae, 5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5))\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet, Search for Alpha, L1 Ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38198 for n = 5 with alpha = 0.07629 and l1 ratio =  0.5\n",
      "MAE = 0.38399 for n = 6 with alpha = 0.04969 and l1 ratio =  0.5\n",
      "MAE = 0.37297 for n = 7 with alpha = 0.04706 and l1 ratio =  0.5\n",
      "MAE = 0.37664 for n = 8 with alpha = 0.03882 and l1 ratio =  0.5\n",
      "MAE = 0.37511 for n = 9 with alpha = 0.02473 and l1 ratio =  0.5\n",
      "MAE = 0.37674 for n = 10 with alpha = 0.02161 and l1 ratio =  0.5\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(fit_intercept=False, normalize=False, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5), \"and l1 ratio = \", model.l1_ratio_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR, C = 0.5, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38731 for n = 5 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39794 for n = 6 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39201 for n = 7 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.39195 for n = 8 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.36879 for n = 9 with C = 0.5 and epsilon = 0.25\n",
      "MAE = 0.36558 for n = 10 with C = 0.5 and epsilon = 0.25\n"
     ]
    }
   ],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import SVR\n",
    "    for C in [0.5]:\n",
    "        model = SVR(kernel='linear', epsilon=eps, C=C)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model on user's data \n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        # unscale\n",
    "        preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "        y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "        # evaluate results\n",
    "        results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "        results_df.columns = ['predicted', 'actual']\n",
    "        results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "        results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "        # Performance Metrics \n",
    "        mae = np.mean(results_df['abs_error'])\n",
    "        print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "              \"with C =\", model.C, \"and epsilon =\", model.epsilon)\n",
    "\n",
    "        quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "        half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "        mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR, Search for C, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.1, 0.2, 0.5, 0.7, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38748 for n = 5 with final params = {'C': 0.2, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.39793 for n = 6 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.3915 for n = 7 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.39195 for n = 8 with final params = {'C': 0.5, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.36878 for n = 9 with final params = {'C': 0.1, 'epsilon': 0.25, 'kernel': 'linear'}\n",
      "MAE = 0.36559 for n = 10 with final params = {'C': 0.7, 'epsilon': 0.25, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import SVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': [eps],\n",
    "            'kernel':['linear']}\n",
    "    svr = SVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some new models..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet, Search for Alpha, Search for L1 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio_space = [.1, .5, .7, .9, .95, .99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38198 for n = 5 with alpha = 0.07629 and l1 ratio =  0.5\n",
      "MAE = 0.38399 for n = 6 with alpha = 0.04969 and l1 ratio =  0.5\n",
      "MAE = 0.37297 for n = 7 with alpha = 0.04706 and l1 ratio =  0.5\n",
      "MAE = 0.37664 for n = 8 with alpha = 0.03882 and l1 ratio =  0.5\n",
      "MAE = 0.3751 for n = 9 with alpha = 0.1153 and l1 ratio =  0.1\n",
      "MAE = 0.37636 for n = 10 with alpha = 0.08173 and l1 ratio =  0.1\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(fit_intercept=False, normalize=False, l1_ratio=l1_ratio_space, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5), \"and l1 ratio = \", model.l1_ratio_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR, Search for C, Epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.1, 0.2, 0.5, 0.7, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.3937 for n = 5 with final params = {'C': 0.2, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39589 for n = 6 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39161 for n = 7 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39468 for n = 8 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.36979 for n = 9 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.3689 for n = 10 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n"
     ]
    }
   ],
   "source": [
    "eps = 0.25\n",
    "\n",
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import LinearSVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': [eps],\n",
    "            'fit_intercept': [False],\n",
    "            'loss': ['epsilon_insensitive'],\n",
    "            'random_state':[rand_state],\n",
    "            'max_iter':[100000]}\n",
    "    svr = LinearSVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR, Search for C, Search for Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.1, 0.2, 0.5, 0.7, 1.0]\n",
    "epsilon_space = [0.25/2, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38888 for n = 5 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39441 for n = 6 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.38772 for n = 7 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39468 for n = 8 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.37835 for n = 9 with final params = {'C': 0.1, 'epsilon': 0.125, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.36786 for n = 10 with final params = {'C': 0.1, 'epsilon': 0.125, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import LinearSVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': epsilon_space,\n",
    "            'fit_intercept': [False],\n",
    "            'loss': ['epsilon_insensitive'],\n",
    "            'random_state':[rand_state],\n",
    "            'max_iter':[100000]}\n",
    "    svr = LinearSVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger Top_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 5, # Points = 1,175\n",
      "N = 6, # Points = 1,375\n",
      "N = 7, # Points = 1,450\n",
      "N = 8, # Points = 3,750\n",
      "N = 9, # Points = 5,125\n",
      "N = 10, # Points = 7,700\n",
      "N = 11, # Points = 8,525\n",
      "N = 12, # Points = 8,550\n",
      "N = 13, # Points = 9,650\n",
      "N = 14, # Points = 10,375\n",
      "N = 15, # Points = 12,250\n",
      "N = 16, # Points = 12,425\n",
      "N = 17, # Points = 12,850\n",
      "N = 18, # Points = 13,000\n",
      "N = 19, # Points = 14,800\n",
      "N = 20, # Points = 15,200\n",
      "N = 21, # Points = 16,450\n",
      "N = 22, # Points = 21,000\n",
      "N = 23, # Points = 21,675\n",
      "N = 24, # Points = 25,075\n",
      "N = 25, # Points = 25,900\n"
     ]
    }
   ],
   "source": [
    "n_users_list = range(5,26)\n",
    "\n",
    "for n in n_users_list:\n",
    "    top_n = list(sim_df.sort_values('sim_score', ascending=False)[0:n]['username'])\n",
    "    top_n_df = df[df['username'].isin(top_n)]\n",
    "    print(\"N = {}, # Points = {:,d}\".format(n, len(top_n_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet, Search for Alpha, Search for L1 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratio_space = [.1, .5, .7, .9, .95, .99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38198 for n = 5 with alpha = 0.07629 and l1 ratio =  0.5\n",
      "MAE = 0.38399 for n = 6 with alpha = 0.04969 and l1 ratio =  0.5\n",
      "MAE = 0.37297 for n = 7 with alpha = 0.04706 and l1 ratio =  0.5\n",
      "MAE = 0.37664 for n = 8 with alpha = 0.03882 and l1 ratio =  0.5\n",
      "MAE = 0.3751 for n = 9 with alpha = 0.1153 and l1 ratio =  0.1\n",
      "MAE = 0.37636 for n = 10 with alpha = 0.08173 and l1 ratio =  0.1\n",
      "MAE = 0.38287 for n = 11 with alpha = 0.08332 and l1 ratio =  0.1\n",
      "MAE = 0.38284 for n = 12 with alpha = 0.08289 and l1 ratio =  0.1\n",
      "MAE = 0.38472 for n = 13 with alpha = 0.11108 and l1 ratio =  0.1\n",
      "MAE = 0.38353 for n = 14 with alpha = 0.09024 and l1 ratio =  0.1\n",
      "MAE = 0.38338 for n = 15 with alpha = 0.06488 and l1 ratio =  0.1\n",
      "MAE = 0.38249 for n = 16 with alpha = 0.06976 and l1 ratio =  0.1\n",
      "MAE = 0.38066 for n = 17 with alpha = 0.07074 and l1 ratio =  0.1\n",
      "MAE = 0.38062 for n = 18 with alpha = 0.06993 and l1 ratio =  0.1\n",
      "MAE = 0.38065 for n = 19 with alpha = 0.08936 and l1 ratio =  0.1\n",
      "MAE = 0.37967 for n = 20 with alpha = 0.07635 and l1 ratio =  0.1\n",
      "MAE = 0.37877 for n = 21 with alpha = 0.07338 and l1 ratio =  0.1\n",
      "MAE = 0.37103 for n = 22 with alpha = 0.07376 and l1 ratio =  0.1\n",
      "MAE = 0.36692 for n = 23 with alpha = 0.06886 and l1 ratio =  0.1\n",
      "MAE = 0.37544 for n = 24 with alpha = 0.07048 and l1 ratio =  0.1\n",
      "MAE = 0.37628 for n = 25 with alpha = 0.05659 and l1 ratio =  0.1\n"
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(fit_intercept=False, normalize=False, l1_ratio=l1_ratio_space, cv=5, random_state=rand_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with alpha =\", np.round(model.alpha_, 5), \"and l1 ratio = \", model.l1_ratio_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVR, Search for C, Search for Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = [0.1, 0.2, 0.5, 0.7, 1.0]\n",
    "epsilon_space = [0.25/2, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.38888 for n = 5 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39441 for n = 6 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.38772 for n = 7 with final params = {'C': 0.1, 'epsilon': 0.5, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n",
      "MAE = 0.39468 for n = 8 with final params = {'C': 0.1, 'epsilon': 0.25, 'fit_intercept': False, 'loss': 'epsilon_insensitive', 'max_iter': 100000, 'random_state': 10}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-a0f4530edac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msvr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Evaluate model on user's data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             epsilon=self.epsilon, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae_list = []\n",
    "quarter_abs_error_list = []\n",
    "half_abs_error_list = []\n",
    "\n",
    "for top_n in n_users_list:\n",
    "    \n",
    "    # split data \n",
    "    df_top_n = df[df['nearest_neighbor_rank'] <= top_n]\n",
    "    X_train = df_top_n[features]\n",
    "    y_train = df_top_n[target]\n",
    "    \n",
    "    X_test = df[df['username'] == user_of_reference][features]\n",
    "    y_test = df[df['username'] == user_of_reference][target]\n",
    "\n",
    "    # train\n",
    "    from sklearn.svm import LinearSVR\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = {'C': C_space,\n",
    "            'epsilon': epsilon_space,\n",
    "            'fit_intercept': [False],\n",
    "            'loss': ['epsilon_insensitive'],\n",
    "            'random_state':[rand_state],\n",
    "            'max_iter':[100000]}\n",
    "    svr = LinearSVR()\n",
    "    model = GridSearchCV(svr, param_grid=grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model on user's data \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # unscale\n",
    "    preds_unscaled = y_scaler.inverse_transform(preds)\n",
    "    y_test_unscaled = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "    # evaluate results\n",
    "    results_df = pd.DataFrame([preds_unscaled, y_test_unscaled]).transpose()\n",
    "    results_df.columns = ['predicted', 'actual']\n",
    "    results_df['error'] = results_df['predicted'] - results_df['actual']\n",
    "    results_df['abs_error'] = abs(results_df['error'])\n",
    "\n",
    "    # Performance Metrics \n",
    "    mae = np.mean(results_df['abs_error'])\n",
    "    print('MAE =', np.round(mae,5), \"for n =\", top_n, \n",
    "          \"with final params =\", model.best_params_)\n",
    "\n",
    "    quarter_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.25])/len(results_df))\n",
    "    half_abs_error_list.append(100*len(results_df[results_df['abs_error']<=0.50])/len(results_df))\n",
    "    mae_list.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up Estimators and Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty estimator dictionary\n",
    "estimator_dict = {}\n",
    "\n",
    "\n",
    "# import GridSearchCV and desired estimators\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "# create models and grids \n",
    "estimator = Lasso()\n",
    "grid = {\n",
    "    'fit_intercept': [False],\n",
    "    'normalize': [False]\n",
    "}\n",
    "estimator_dict['elasticnet'] = {'estimator':estimator, 'grid':grid}\n",
    "\n",
    "\n",
    "estimator = ElasticNet()\n",
    "grid = {\n",
    "    'fit_intercept': [False],\n",
    "    'normalize': [False]\n",
    "}\n",
    "estimator_dict['elasticnet'] = {'estimator':estimator, 'grid':grid}\n",
    "\n",
    "\n",
    "# estimator = SVR()\n",
    "# grid = {\n",
    "#     'epsilon': np.linspace(0.25/2, 0.5, 10),\n",
    "#     'C': np.linspace(1.0, 10, 10),\n",
    "#     'fit_intercept': [True, False],\n",
    "#     'max_iter': [10000]\n",
    "# }\n",
    "\n",
    "estimator_dict['linearsvr'] = {'estimator':estimator, 'grid':grid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Set Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_gridsearchCV(estimator_dict, X_train, y_train):\n",
    "    \n",
    "    # grid search for each estimator, store best params and scores for each estimator\n",
    "    for key in estimator_dict.keys():\n",
    "        \n",
    "        # build gridsearchcv\n",
    "        gridsearchcv = GridSearchCV(estimator = estimator_dict[key]['estimator'], \n",
    "                                    param_grid = estimator_dict[key]['grid'],\n",
    "                                    cv=3, scoring=scoring, return_train_score=True, iid=True)\n",
    "\n",
    "        # silence SVR convergence warnings \n",
    "        import warnings\n",
    "        warnings.filterwarnings('ignore', 'Liblinear failed to converge,*')\n",
    "\n",
    "        # fit gridsearchcv\n",
    "        gridsearchcv.fit(X_train, y_train)\n",
    "\n",
    "        # gather results \n",
    "        estimator_dict[key]['nearest_neighbors'] = 'ALL'\n",
    "        estimator_dict[key]['n_training_points'] = len(X_train)\n",
    "        estimator_dict[key]['best_params'] = gridsearchcv.best_params_\n",
    "        estimator_dict[key][scoring] = gridsearchcv.best_score_\n",
    "        estimator_dict[key]['stdev'] = gridsearchcv.cv_results_['std_test_score'][gridsearchcv.best_index_]\n",
    "        \n",
    "        results_dict = estimator_dict\n",
    "\n",
    "    return(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_guild",
   "language": "python",
   "name": "ml_guild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
